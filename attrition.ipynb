{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bmckimmy/neural-network-challenge-2/blob/main/attrition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alIIEHibGc3M"
      },
      "source": [
        "## Part 1: Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "6eDUJ4NtGc3P",
        "outputId": "5fab5113-a3c1-470a-a670-2232f1a0a421"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age Attrition     BusinessTravel              Department  DistanceFromHome  \\\n",
              "0   41       Yes      Travel_Rarely                   Sales                 1   \n",
              "1   49        No  Travel_Frequently  Research & Development                 8   \n",
              "2   37       Yes      Travel_Rarely  Research & Development                 2   \n",
              "3   33        No  Travel_Frequently  Research & Development                 3   \n",
              "4   27        No      Travel_Rarely  Research & Development                 2   \n",
              "\n",
              "   Education EducationField  EnvironmentSatisfaction  HourlyRate  \\\n",
              "0          2  Life Sciences                        2          94   \n",
              "1          1  Life Sciences                        3          61   \n",
              "2          2          Other                        4          92   \n",
              "3          4  Life Sciences                        4          56   \n",
              "4          1        Medical                        1          40   \n",
              "\n",
              "   JobInvolvement  ...  PerformanceRating RelationshipSatisfaction  \\\n",
              "0               3  ...                  3                        1   \n",
              "1               2  ...                  4                        4   \n",
              "2               2  ...                  3                        2   \n",
              "3               3  ...                  3                        3   \n",
              "4               3  ...                  3                        4   \n",
              "\n",
              "   StockOptionLevel TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  \\\n",
              "0                 0                 8                      0               1   \n",
              "1                 1                10                      3               3   \n",
              "2                 0                 7                      3               3   \n",
              "3                 0                 8                      3               3   \n",
              "4                 1                 6                      3               3   \n",
              "\n",
              "   YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
              "0               6                   4                        0   \n",
              "1              10                   7                        1   \n",
              "2               0                   0                        0   \n",
              "3               8                   7                        3   \n",
              "4               2                   2                        2   \n",
              "\n",
              "   YearsWithCurrManager  \n",
              "0                     5  \n",
              "1                     7  \n",
              "2                     0  \n",
              "3                     0  \n",
              "4                     2  \n",
              "\n",
              "[5 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83ab0e80-f6d3-4f1a-89bd-8b67a3a11b49\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Attrition</th>\n",
              "      <th>BusinessTravel</th>\n",
              "      <th>Department</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EducationField</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>...</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>Sales</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>2</td>\n",
              "      <td>94</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49</td>\n",
              "      <td>No</td>\n",
              "      <td>Travel_Frequently</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>3</td>\n",
              "      <td>61</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Other</td>\n",
              "      <td>4</td>\n",
              "      <td>92</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>No</td>\n",
              "      <td>Travel_Frequently</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>4</td>\n",
              "      <td>56</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27</td>\n",
              "      <td>No</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Medical</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 27 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83ab0e80-f6d3-4f1a-89bd-8b67a3a11b49')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-83ab0e80-f6d3-4f1a-89bd-8b67a3a11b49 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-83ab0e80-f6d3-4f1a-89bd-8b67a3a11b49');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7bbfb885-9445-4200-b9cd-8783b0b1acf4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7bbfb885-9445-4200-b9cd-8783b0b1acf4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7bbfb885-9445-4200-b9cd-8783b0b1acf4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "attrition_df"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#  Import and read the attrition data\n",
        "attrition_df = pd.read_csv('https://static.bc-edx.com/ai/ail-v-1-0/m19/lms/datasets/attrition.csv')\n",
        "attrition_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g22aQSY4Gc3Q",
        "outputId": "6cc8ca28-6008-46e0-9c77-defa6e512551"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age                         43\n",
              "Attrition                    2\n",
              "BusinessTravel               3\n",
              "Department                   3\n",
              "DistanceFromHome            29\n",
              "Education                    5\n",
              "EducationField               6\n",
              "EnvironmentSatisfaction      4\n",
              "HourlyRate                  71\n",
              "JobInvolvement               4\n",
              "JobLevel                     5\n",
              "JobRole                      9\n",
              "JobSatisfaction              4\n",
              "MaritalStatus                3\n",
              "NumCompaniesWorked          10\n",
              "OverTime                     2\n",
              "PercentSalaryHike           15\n",
              "PerformanceRating            2\n",
              "RelationshipSatisfaction     4\n",
              "StockOptionLevel             4\n",
              "TotalWorkingYears           40\n",
              "TrainingTimesLastYear        7\n",
              "WorkLifeBalance              4\n",
              "YearsAtCompany              37\n",
              "YearsInCurrentRole          19\n",
              "YearsSinceLastPromotion     16\n",
              "YearsWithCurrManager        18\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "# Determine the number of unique values in each column.\n",
        "attrition_df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "50vMgBEnJbfM"
      },
      "outputs": [],
      "source": [
        "# Create y_df with the Attrition and Department columns\n",
        "y_df = attrition_df[['Attrition', 'Department']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Virka0zLGc3R",
        "outputId": "e33caffc-4687-4f83-e103-edeec38aaf4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Education                   int64\n",
              "Age                         int64\n",
              "DistanceFromHome            int64\n",
              "JobSatisfaction             int64\n",
              "OverTime                   object\n",
              "StockOptionLevel            int64\n",
              "WorkLifeBalance             int64\n",
              "YearsAtCompany              int64\n",
              "YearsSinceLastPromotion     int64\n",
              "NumCompaniesWorked          int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "# Create a list of at least 10 column names to use as X data\n",
        "selected_columns = [\n",
        "    'Education',\n",
        "    'Age',\n",
        "    'DistanceFromHome',\n",
        "    'JobSatisfaction',\n",
        "    'OverTime',\n",
        "    'StockOptionLevel',\n",
        "    'WorkLifeBalance',\n",
        "    'YearsAtCompany',\n",
        "    'YearsSinceLastPromotion',\n",
        "    'NumCompaniesWorked',\n",
        "]\n",
        "\n",
        "# Create X_df using your selected columns\n",
        "X_df = attrition_df[selected_columns]\n",
        "\n",
        "# Show the data types for X_df\n",
        "X_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "KaJfdOGUMHMR"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYubUJqiLCSp",
        "outputId": "6dad3d1b-16d8-4b82-e712-d8ccec37e83a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-96-520122f26c80>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_df['OverTime'] = X_df['OverTime'].map({'Yes': 1, 'No': 0})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "No     1054\n",
              "Yes     416\n",
              "Name: OverTime, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "# Convert your X data to numeric data types however you see fit\n",
        "# Add new code cells as necessary\n",
        "X_df['OverTime'] = X_df['OverTime'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# For the target variable, let's assume we are predicting 'Attrition', and convert it to numeric as well\n",
        "y_df = attrition_df['Attrition'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Verifying the conversion for 'OverTime' and showing the shapes of the split datasets as a simple verification step\n",
        "X_df['OverTime'].dtype, X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "overtime_counts = attrition_df['OverTime'].value_counts()\n",
        "overtime_counts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "EWA-aIA5Gc3T"
      },
      "outputs": [],
      "source": [
        "# Create a StandardScaler\n",
        "scaler_final = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler to the training data\n",
        "X_train_scaled_final = scaler_final.fit_transform(X_train)\n",
        "\n",
        "# Scale the training and testing data\n",
        "X_test_scaled_final = scaler_final.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z0Mky8vQSz4",
        "outputId": "ec1bfd79-3f1b-46ac-9d65-e12caff61ab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "# Perform the train-test split on the entire dataset\n",
        "X = attrition_df.drop(columns='Attrition')  # assuming 'Attrition' is the target variable\n",
        "y = attrition_df['Attrition']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a OneHotEncoder for the Department column\n",
        "department_train = X_train['Department'].values.reshape(-1, 1)\n",
        "department_test = X_test['Department'].values.reshape(-1, 1)\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Fit the encoder to the training data\n",
        "# Create two new variables by applying the encoder\n",
        "department_train_encoded = encoder.fit_transform(department_train)\n",
        "department_test_encoded = encoder.transform(department_test)\n",
        "\n",
        "department_test_encoded\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a OneHotEncoder for the Attrition column\n",
        "attrition_train = y_train.values.reshape(-1, 1)\n",
        "attrition_test = y_test.values.reshape(-1, 1)\n",
        "\n",
        "# Fit the encoder to the training data\n",
        "attrition_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Create two new variables by applying the encoder\n",
        "# to the training and testing data\n",
        "attrition_train_encoded = attrition_encoder.fit_transform(attrition_train)\n",
        "attrition_test_encoded = attrition_encoder.transform(attrition_test)\n",
        "attrition_test_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAfku95Lu83Z",
        "outputId": "58eef3d6-6b85-4cbc-8f0f-e0dee898ea7d"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykNmu_WWGc3T"
      },
      "source": [
        "## Create, Compile, and Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "WUptZqmSGc3T"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "# Find the number of columns in the X training data\n",
        "number_of_features = X_train_scaled_final.shape[1]\n",
        "\n",
        "# Create the input layer\n",
        "input_layer = Input(shape=(10,), name='input')\n",
        "\n",
        "# Create at least two shared layers\n",
        "shared1 = Dense(64, activation='relu', name='shared1')(input_layer)\n",
        "shared2 = Dense(128, activation='relu', name='shared2')(shared1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "JukjTm2yTEqd"
      },
      "outputs": [],
      "source": [
        "# Create a branch for Department\n",
        "# with a hidden layer and an output layer\n",
        "\n",
        "# Create the hidden layer\n",
        "department_hidden = Dense(32, activation='relu', name='department_hidden')(shared2)\n",
        "\n",
        "# Create the output layer\n",
        "department_output = Dense(3, activation='softmax', name='department_output')(department_hidden)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "9OqhUiOJUBkR"
      },
      "outputs": [],
      "source": [
        "# Create a branch for Attrition\n",
        "# with a hidden layer and an output layer\n",
        "\n",
        "# Create the hidden layer\n",
        "attrition_hidden = Dense(32, activation='relu', name='attrition_hidden')(shared2)\n",
        "\n",
        "# Create the output layer\n",
        "attrition_output = Dense(2, activation='softmax', name='attrition_output')(attrition_hidden)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = Model(inputs=input_layer, outputs=[department_output, attrition_output], name='model')\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss={'department_output': 'categorical_crossentropy', 'attrition_output': 'categorical_crossentropy'},\n",
        "              metrics={'department_output': 'accuracy', 'attrition_output': 'accuracy'})\n",
        "\n",
        "# Summarize the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amEQGV0Wy2Rt",
        "outputId": "0cd045d4-8309-449b-ae36-7128945fa994"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input (InputLayer)          [(None, 10)]                 0         []                            \n",
            "                                                                                                  \n",
            " shared1 (Dense)             (None, 64)                   704       ['input[0][0]']               \n",
            "                                                                                                  \n",
            " shared2 (Dense)             (None, 128)                  8320      ['shared1[0][0]']             \n",
            "                                                                                                  \n",
            " department_hidden (Dense)   (None, 32)                   4128      ['shared2[0][0]']             \n",
            "                                                                                                  \n",
            " attrition_hidden (Dense)    (None, 32)                   4128      ['shared2[0][0]']             \n",
            "                                                                                                  \n",
            " department_output (Dense)   (None, 3)                    99        ['department_hidden[0][0]']   \n",
            "                                                                                                  \n",
            " attrition_output (Dense)    (None, 2)                    66        ['attrition_hidden[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17445 (68.14 KB)\n",
            "Trainable params: 17445 (68.14 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    x=X_train_scaled_final,  # Your scaled input features\n",
        "    y={\n",
        "        'department_output': department_train_encoded,  # Your encoded department labels\n",
        "        'attrition_output': attrition_train_encoded  # Your encoded attrition labels\n",
        "    },\n",
        "    validation_data=(\n",
        "        X_test_scaled_final,\n",
        "        {\n",
        "            'department_output': department_test_encoded,  # Your encoded department validation labels\n",
        "            'attrition_output': attrition_test_encoded  # Your encoded attrition validation labels\n",
        "        }\n",
        "    ),\n",
        "    epochs=100,  # Number of epochs to train for\n",
        "    batch_size=34,  # Number of samples per gradient update\n",
        "    verbose=1  # Show progress bar\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRQ9n37W1kkM",
        "outputId": "89ed2683-000b-4c4b-8f67-dc421c324462"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "35/35 [==============================] - 2s 15ms/step - loss: 1.3528 - department_output_loss: 0.8570 - attrition_output_loss: 0.4958 - department_output_accuracy: 0.6301 - attrition_output_accuracy: 0.8078 - val_loss: 1.1830 - val_department_output_loss: 0.7886 - val_attrition_output_loss: 0.3945 - val_department_output_accuracy: 0.6667 - val_attrition_output_accuracy: 0.8673\n",
            "Epoch 2/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 1.1839 - department_output_loss: 0.7834 - attrition_output_loss: 0.4006 - department_output_accuracy: 0.6497 - attrition_output_accuracy: 0.8418 - val_loss: 1.1652 - val_department_output_loss: 0.7796 - val_attrition_output_loss: 0.3856 - val_department_output_accuracy: 0.6667 - val_attrition_output_accuracy: 0.8707\n",
            "Epoch 3/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 1.1492 - department_output_loss: 0.7669 - attrition_output_loss: 0.3823 - department_output_accuracy: 0.6505 - attrition_output_accuracy: 0.8495 - val_loss: 1.1853 - val_department_output_loss: 0.7821 - val_attrition_output_loss: 0.4032 - val_department_output_accuracy: 0.6667 - val_attrition_output_accuracy: 0.8435\n",
            "Epoch 4/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 1.1279 - department_output_loss: 0.7582 - attrition_output_loss: 0.3697 - department_output_accuracy: 0.6505 - attrition_output_accuracy: 0.8546 - val_loss: 1.1623 - val_department_output_loss: 0.7860 - val_attrition_output_loss: 0.3763 - val_department_output_accuracy: 0.6701 - val_attrition_output_accuracy: 0.8571\n",
            "Epoch 5/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 1.1109 - department_output_loss: 0.7500 - attrition_output_loss: 0.3610 - department_output_accuracy: 0.6514 - attrition_output_accuracy: 0.8605 - val_loss: 1.1565 - val_department_output_loss: 0.7829 - val_attrition_output_loss: 0.3736 - val_department_output_accuracy: 0.6667 - val_attrition_output_accuracy: 0.8537\n",
            "Epoch 6/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 1.0965 - department_output_loss: 0.7470 - attrition_output_loss: 0.3494 - department_output_accuracy: 0.6446 - attrition_output_accuracy: 0.8597 - val_loss: 1.1585 - val_department_output_loss: 0.7872 - val_attrition_output_loss: 0.3712 - val_department_output_accuracy: 0.6667 - val_attrition_output_accuracy: 0.8639\n",
            "Epoch 7/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 1.0789 - department_output_loss: 0.7403 - attrition_output_loss: 0.3386 - department_output_accuracy: 0.6497 - attrition_output_accuracy: 0.8665 - val_loss: 1.1556 - val_department_output_loss: 0.7897 - val_attrition_output_loss: 0.3658 - val_department_output_accuracy: 0.6667 - val_attrition_output_accuracy: 0.8571\n",
            "Epoch 8/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.0624 - department_output_loss: 0.7328 - attrition_output_loss: 0.3295 - department_output_accuracy: 0.6514 - attrition_output_accuracy: 0.8690 - val_loss: 1.1620 - val_department_output_loss: 0.7944 - val_attrition_output_loss: 0.3676 - val_department_output_accuracy: 0.6667 - val_attrition_output_accuracy: 0.8639\n",
            "Epoch 9/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 1.0464 - department_output_loss: 0.7236 - attrition_output_loss: 0.3228 - department_output_accuracy: 0.6522 - attrition_output_accuracy: 0.8665 - val_loss: 1.1637 - val_department_output_loss: 0.7969 - val_attrition_output_loss: 0.3668 - val_department_output_accuracy: 0.6497 - val_attrition_output_accuracy: 0.8639\n",
            "Epoch 10/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 1.0304 - department_output_loss: 0.7138 - attrition_output_loss: 0.3166 - department_output_accuracy: 0.6692 - attrition_output_accuracy: 0.8776 - val_loss: 1.1782 - val_department_output_loss: 0.7990 - val_attrition_output_loss: 0.3792 - val_department_output_accuracy: 0.6599 - val_attrition_output_accuracy: 0.8810\n",
            "Epoch 11/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.0160 - department_output_loss: 0.7067 - attrition_output_loss: 0.3093 - department_output_accuracy: 0.6573 - attrition_output_accuracy: 0.8784 - val_loss: 1.1764 - val_department_output_loss: 0.8048 - val_attrition_output_loss: 0.3716 - val_department_output_accuracy: 0.6463 - val_attrition_output_accuracy: 0.8707\n",
            "Epoch 12/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 1.0064 - department_output_loss: 0.7036 - attrition_output_loss: 0.3027 - department_output_accuracy: 0.6760 - attrition_output_accuracy: 0.8784 - val_loss: 1.2050 - val_department_output_loss: 0.8180 - val_attrition_output_loss: 0.3870 - val_department_output_accuracy: 0.6599 - val_attrition_output_accuracy: 0.8639\n",
            "Epoch 13/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.9917 - department_output_loss: 0.6915 - attrition_output_loss: 0.3002 - department_output_accuracy: 0.6675 - attrition_output_accuracy: 0.8801 - val_loss: 1.1937 - val_department_output_loss: 0.8138 - val_attrition_output_loss: 0.3799 - val_department_output_accuracy: 0.6497 - val_attrition_output_accuracy: 0.8673\n",
            "Epoch 14/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.9709 - department_output_loss: 0.6819 - attrition_output_loss: 0.2890 - department_output_accuracy: 0.6769 - attrition_output_accuracy: 0.8844 - val_loss: 1.2202 - val_department_output_loss: 0.8296 - val_attrition_output_loss: 0.3905 - val_department_output_accuracy: 0.6429 - val_attrition_output_accuracy: 0.8776\n",
            "Epoch 15/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.9521 - department_output_loss: 0.6706 - attrition_output_loss: 0.2814 - department_output_accuracy: 0.6913 - attrition_output_accuracy: 0.8912 - val_loss: 1.2200 - val_department_output_loss: 0.8426 - val_attrition_output_loss: 0.3774 - val_department_output_accuracy: 0.5918 - val_attrition_output_accuracy: 0.8810\n",
            "Epoch 16/100\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.9337 - department_output_loss: 0.6592 - attrition_output_loss: 0.2744 - department_output_accuracy: 0.6956 - attrition_output_accuracy: 0.8844 - val_loss: 1.2223 - val_department_output_loss: 0.8240 - val_attrition_output_loss: 0.3984 - val_department_output_accuracy: 0.6361 - val_attrition_output_accuracy: 0.8639\n",
            "Epoch 17/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.9166 - department_output_loss: 0.6465 - attrition_output_loss: 0.2701 - department_output_accuracy: 0.7168 - attrition_output_accuracy: 0.8946 - val_loss: 1.2496 - val_department_output_loss: 0.8501 - val_attrition_output_loss: 0.3995 - val_department_output_accuracy: 0.6293 - val_attrition_output_accuracy: 0.8673\n",
            "Epoch 18/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.8981 - department_output_loss: 0.6356 - attrition_output_loss: 0.2625 - department_output_accuracy: 0.7160 - attrition_output_accuracy: 0.8929 - val_loss: 1.2623 - val_department_output_loss: 0.8563 - val_attrition_output_loss: 0.4060 - val_department_output_accuracy: 0.6122 - val_attrition_output_accuracy: 0.8776\n",
            "Epoch 19/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.8826 - department_output_loss: 0.6268 - attrition_output_loss: 0.2558 - department_output_accuracy: 0.7177 - attrition_output_accuracy: 0.9022 - val_loss: 1.2697 - val_department_output_loss: 0.8705 - val_attrition_output_loss: 0.3992 - val_department_output_accuracy: 0.5918 - val_attrition_output_accuracy: 0.8810\n",
            "Epoch 20/100\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.8667 - department_output_loss: 0.6112 - attrition_output_loss: 0.2555 - department_output_accuracy: 0.7355 - attrition_output_accuracy: 0.8937 - val_loss: 1.3105 - val_department_output_loss: 0.8742 - val_attrition_output_loss: 0.4364 - val_department_output_accuracy: 0.5918 - val_attrition_output_accuracy: 0.8673\n",
            "Epoch 21/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.8592 - department_output_loss: 0.6137 - attrition_output_loss: 0.2455 - department_output_accuracy: 0.7330 - attrition_output_accuracy: 0.8980 - val_loss: 1.3303 - val_department_output_loss: 0.9036 - val_attrition_output_loss: 0.4267 - val_department_output_accuracy: 0.6361 - val_attrition_output_accuracy: 0.8741\n",
            "Epoch 22/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.8277 - department_output_loss: 0.5888 - attrition_output_loss: 0.2389 - department_output_accuracy: 0.7560 - attrition_output_accuracy: 0.9039 - val_loss: 1.3232 - val_department_output_loss: 0.9040 - val_attrition_output_loss: 0.4192 - val_department_output_accuracy: 0.6122 - val_attrition_output_accuracy: 0.8776\n",
            "Epoch 23/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.8144 - department_output_loss: 0.5777 - attrition_output_loss: 0.2368 - department_output_accuracy: 0.7500 - attrition_output_accuracy: 0.9014 - val_loss: 1.3826 - val_department_output_loss: 0.9481 - val_attrition_output_loss: 0.4345 - val_department_output_accuracy: 0.5272 - val_attrition_output_accuracy: 0.8810\n",
            "Epoch 24/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.7971 - department_output_loss: 0.5662 - attrition_output_loss: 0.2309 - department_output_accuracy: 0.7611 - attrition_output_accuracy: 0.8997 - val_loss: 1.4051 - val_department_output_loss: 0.9409 - val_attrition_output_loss: 0.4642 - val_department_output_accuracy: 0.5952 - val_attrition_output_accuracy: 0.8435\n",
            "Epoch 25/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.7828 - department_output_loss: 0.5512 - attrition_output_loss: 0.2316 - department_output_accuracy: 0.7670 - attrition_output_accuracy: 0.9073 - val_loss: 1.3974 - val_department_output_loss: 0.9575 - val_attrition_output_loss: 0.4399 - val_department_output_accuracy: 0.5850 - val_attrition_output_accuracy: 0.8810\n",
            "Epoch 26/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.7492 - department_output_loss: 0.5335 - attrition_output_loss: 0.2157 - department_output_accuracy: 0.7789 - attrition_output_accuracy: 0.9082 - val_loss: 1.4604 - val_department_output_loss: 0.9722 - val_attrition_output_loss: 0.4882 - val_department_output_accuracy: 0.5544 - val_attrition_output_accuracy: 0.8435\n",
            "Epoch 27/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.7349 - department_output_loss: 0.5146 - attrition_output_loss: 0.2204 - department_output_accuracy: 0.7849 - attrition_output_accuracy: 0.9031 - val_loss: 1.4801 - val_department_output_loss: 1.0147 - val_attrition_output_loss: 0.4654 - val_department_output_accuracy: 0.5306 - val_attrition_output_accuracy: 0.8810\n",
            "Epoch 28/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.7036 - department_output_loss: 0.5017 - attrition_output_loss: 0.2019 - department_output_accuracy: 0.7891 - attrition_output_accuracy: 0.9175 - val_loss: 1.4737 - val_department_output_loss: 0.9876 - val_attrition_output_loss: 0.4861 - val_department_output_accuracy: 0.5714 - val_attrition_output_accuracy: 0.8435\n",
            "Epoch 29/100\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.6866 - department_output_loss: 0.4926 - attrition_output_loss: 0.1940 - department_output_accuracy: 0.7968 - attrition_output_accuracy: 0.9218 - val_loss: 1.5401 - val_department_output_loss: 1.0558 - val_attrition_output_loss: 0.4844 - val_department_output_accuracy: 0.5374 - val_attrition_output_accuracy: 0.8707\n",
            "Epoch 30/100\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.6562 - department_output_loss: 0.4680 - attrition_output_loss: 0.1882 - department_output_accuracy: 0.8087 - attrition_output_accuracy: 0.9286 - val_loss: 1.5591 - val_department_output_loss: 1.0618 - val_attrition_output_loss: 0.4973 - val_department_output_accuracy: 0.5680 - val_attrition_output_accuracy: 0.8571\n",
            "Epoch 31/100\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.6521 - department_output_loss: 0.4678 - attrition_output_loss: 0.1843 - department_output_accuracy: 0.8095 - attrition_output_accuracy: 0.9260 - val_loss: 1.5605 - val_department_output_loss: 1.0605 - val_attrition_output_loss: 0.5000 - val_department_output_accuracy: 0.5340 - val_attrition_output_accuracy: 0.8810\n",
            "Epoch 32/100\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.6224 - department_output_loss: 0.4467 - attrition_output_loss: 0.1758 - department_output_accuracy: 0.8061 - attrition_output_accuracy: 0.9294 - val_loss: 1.6048 - val_department_output_loss: 1.0756 - val_attrition_output_loss: 0.5292 - val_department_output_accuracy: 0.5068 - val_attrition_output_accuracy: 0.8265\n",
            "Epoch 33/100\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.6272 - department_output_loss: 0.4508 - attrition_output_loss: 0.1764 - department_output_accuracy: 0.8206 - attrition_output_accuracy: 0.9362 - val_loss: 1.6340 - val_department_output_loss: 1.1059 - val_attrition_output_loss: 0.5281 - val_department_output_accuracy: 0.5306 - val_attrition_output_accuracy: 0.8776\n",
            "Epoch 34/100\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.5906 - department_output_loss: 0.4204 - attrition_output_loss: 0.1702 - department_output_accuracy: 0.8350 - attrition_output_accuracy: 0.9311 - val_loss: 1.6684 - val_department_output_loss: 1.1072 - val_attrition_output_loss: 0.5612 - val_department_output_accuracy: 0.5238 - val_attrition_output_accuracy: 0.8027\n",
            "Epoch 35/100\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.5889 - department_output_loss: 0.4244 - attrition_output_loss: 0.1644 - department_output_accuracy: 0.8350 - attrition_output_accuracy: 0.9413 - val_loss: 1.7031 - val_department_output_loss: 1.1567 - val_attrition_output_loss: 0.5464 - val_department_output_accuracy: 0.4898 - val_attrition_output_accuracy: 0.8707\n",
            "Epoch 36/100\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.5618 - department_output_loss: 0.4023 - attrition_output_loss: 0.1595 - department_output_accuracy: 0.8418 - attrition_output_accuracy: 0.9396 - val_loss: 1.7135 - val_department_output_loss: 1.1555 - val_attrition_output_loss: 0.5579 - val_department_output_accuracy: 0.5782 - val_attrition_output_accuracy: 0.8333\n",
            "Epoch 37/100\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.5213 - department_output_loss: 0.3754 - attrition_output_loss: 0.1460 - department_output_accuracy: 0.8563 - attrition_output_accuracy: 0.9532 - val_loss: 1.8109 - val_department_output_loss: 1.2112 - val_attrition_output_loss: 0.5997 - val_department_output_accuracy: 0.5204 - val_attrition_output_accuracy: 0.8503\n",
            "Epoch 38/100\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.5146 - department_output_loss: 0.3716 - attrition_output_loss: 0.1430 - department_output_accuracy: 0.8665 - attrition_output_accuracy: 0.9490 - val_loss: 1.8231 - val_department_output_loss: 1.2357 - val_attrition_output_loss: 0.5874 - val_department_output_accuracy: 0.5714 - val_attrition_output_accuracy: 0.8639\n",
            "Epoch 39/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.4963 - department_output_loss: 0.3607 - attrition_output_loss: 0.1356 - department_output_accuracy: 0.8605 - attrition_output_accuracy: 0.9541 - val_loss: 1.8677 - val_department_output_loss: 1.2681 - val_attrition_output_loss: 0.5996 - val_department_output_accuracy: 0.5850 - val_attrition_output_accuracy: 0.8401\n",
            "Epoch 40/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4833 - department_output_loss: 0.3482 - attrition_output_loss: 0.1351 - department_output_accuracy: 0.8741 - attrition_output_accuracy: 0.9507 - val_loss: 1.8975 - val_department_output_loss: 1.2671 - val_attrition_output_loss: 0.6304 - val_department_output_accuracy: 0.5374 - val_attrition_output_accuracy: 0.8571\n",
            "Epoch 41/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4671 - department_output_loss: 0.3271 - attrition_output_loss: 0.1401 - department_output_accuracy: 0.8835 - attrition_output_accuracy: 0.9481 - val_loss: 1.9201 - val_department_output_loss: 1.2992 - val_attrition_output_loss: 0.6208 - val_department_output_accuracy: 0.5850 - val_attrition_output_accuracy: 0.8231\n",
            "Epoch 42/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4556 - department_output_loss: 0.3245 - attrition_output_loss: 0.1311 - department_output_accuracy: 0.8835 - attrition_output_accuracy: 0.9566 - val_loss: 1.9918 - val_department_output_loss: 1.3509 - val_attrition_output_loss: 0.6409 - val_department_output_accuracy: 0.5918 - val_attrition_output_accuracy: 0.8605\n",
            "Epoch 43/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4347 - department_output_loss: 0.3106 - attrition_output_loss: 0.1241 - department_output_accuracy: 0.9022 - attrition_output_accuracy: 0.9566 - val_loss: 2.0298 - val_department_output_loss: 1.3558 - val_attrition_output_loss: 0.6740 - val_department_output_accuracy: 0.5374 - val_attrition_output_accuracy: 0.8707\n",
            "Epoch 44/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.4206 - department_output_loss: 0.3085 - attrition_output_loss: 0.1121 - department_output_accuracy: 0.8988 - attrition_output_accuracy: 0.9643 - val_loss: 2.0629 - val_department_output_loss: 1.4026 - val_attrition_output_loss: 0.6603 - val_department_output_accuracy: 0.5748 - val_attrition_output_accuracy: 0.8673\n",
            "Epoch 45/100\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.3977 - department_output_loss: 0.2899 - attrition_output_loss: 0.1077 - department_output_accuracy: 0.9022 - attrition_output_accuracy: 0.9660 - val_loss: 2.1519 - val_department_output_loss: 1.4665 - val_attrition_output_loss: 0.6854 - val_department_output_accuracy: 0.5918 - val_attrition_output_accuracy: 0.8435\n",
            "Epoch 46/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3820 - department_output_loss: 0.2770 - attrition_output_loss: 0.1050 - department_output_accuracy: 0.9124 - attrition_output_accuracy: 0.9702 - val_loss: 2.1128 - val_department_output_loss: 1.4051 - val_attrition_output_loss: 0.7077 - val_department_output_accuracy: 0.5476 - val_attrition_output_accuracy: 0.8537\n",
            "Epoch 47/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3636 - department_output_loss: 0.2646 - attrition_output_loss: 0.0991 - department_output_accuracy: 0.9158 - attrition_output_accuracy: 0.9719 - val_loss: 2.1361 - val_department_output_loss: 1.4199 - val_attrition_output_loss: 0.7162 - val_department_output_accuracy: 0.5272 - val_attrition_output_accuracy: 0.8503\n",
            "Epoch 48/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3614 - department_output_loss: 0.2594 - attrition_output_loss: 0.1020 - department_output_accuracy: 0.9192 - attrition_output_accuracy: 0.9651 - val_loss: 2.1703 - val_department_output_loss: 1.4234 - val_attrition_output_loss: 0.7469 - val_department_output_accuracy: 0.5374 - val_attrition_output_accuracy: 0.8469\n",
            "Epoch 49/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3461 - department_output_loss: 0.2444 - attrition_output_loss: 0.1016 - department_output_accuracy: 0.9303 - attrition_output_accuracy: 0.9668 - val_loss: 2.1844 - val_department_output_loss: 1.4610 - val_attrition_output_loss: 0.7234 - val_department_output_accuracy: 0.5544 - val_attrition_output_accuracy: 0.8469\n",
            "Epoch 50/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3260 - department_output_loss: 0.2349 - attrition_output_loss: 0.0911 - department_output_accuracy: 0.9243 - attrition_output_accuracy: 0.9702 - val_loss: 2.2138 - val_department_output_loss: 1.4688 - val_attrition_output_loss: 0.7450 - val_department_output_accuracy: 0.5510 - val_attrition_output_accuracy: 0.8231\n",
            "Epoch 51/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3195 - department_output_loss: 0.2297 - attrition_output_loss: 0.0898 - department_output_accuracy: 0.9294 - attrition_output_accuracy: 0.9745 - val_loss: 2.3117 - val_department_output_loss: 1.5237 - val_attrition_output_loss: 0.7879 - val_department_output_accuracy: 0.5408 - val_attrition_output_accuracy: 0.7925\n",
            "Epoch 52/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.3111 - department_output_loss: 0.2166 - attrition_output_loss: 0.0945 - department_output_accuracy: 0.9413 - attrition_output_accuracy: 0.9719 - val_loss: 2.3349 - val_department_output_loss: 1.5745 - val_attrition_output_loss: 0.7604 - val_department_output_accuracy: 0.5544 - val_attrition_output_accuracy: 0.8333\n",
            "Epoch 53/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2898 - department_output_loss: 0.2087 - attrition_output_loss: 0.0811 - department_output_accuracy: 0.9413 - attrition_output_accuracy: 0.9762 - val_loss: 2.3937 - val_department_output_loss: 1.5967 - val_attrition_output_loss: 0.7970 - val_department_output_accuracy: 0.5578 - val_attrition_output_accuracy: 0.8095\n",
            "Epoch 54/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2708 - department_output_loss: 0.1931 - attrition_output_loss: 0.0777 - department_output_accuracy: 0.9507 - attrition_output_accuracy: 0.9779 - val_loss: 2.4209 - val_department_output_loss: 1.6288 - val_attrition_output_loss: 0.7921 - val_department_output_accuracy: 0.5408 - val_attrition_output_accuracy: 0.8367\n",
            "Epoch 55/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2614 - department_output_loss: 0.1848 - attrition_output_loss: 0.0767 - department_output_accuracy: 0.9490 - attrition_output_accuracy: 0.9770 - val_loss: 2.4305 - val_department_output_loss: 1.6220 - val_attrition_output_loss: 0.8085 - val_department_output_accuracy: 0.5136 - val_attrition_output_accuracy: 0.8435\n",
            "Epoch 56/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2663 - department_output_loss: 0.1844 - attrition_output_loss: 0.0819 - department_output_accuracy: 0.9524 - attrition_output_accuracy: 0.9702 - val_loss: 2.5187 - val_department_output_loss: 1.6560 - val_attrition_output_loss: 0.8627 - val_department_output_accuracy: 0.5646 - val_attrition_output_accuracy: 0.8231\n",
            "Epoch 57/100\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.2536 - department_output_loss: 0.1827 - attrition_output_loss: 0.0709 - department_output_accuracy: 0.9413 - attrition_output_accuracy: 0.9787 - val_loss: 2.5888 - val_department_output_loss: 1.7466 - val_attrition_output_loss: 0.8422 - val_department_output_accuracy: 0.4932 - val_attrition_output_accuracy: 0.8333\n",
            "Epoch 58/100\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.2455 - department_output_loss: 0.1773 - attrition_output_loss: 0.0682 - department_output_accuracy: 0.9498 - attrition_output_accuracy: 0.9796 - val_loss: 2.5512 - val_department_output_loss: 1.7191 - val_attrition_output_loss: 0.8320 - val_department_output_accuracy: 0.5578 - val_attrition_output_accuracy: 0.8401\n",
            "Epoch 59/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2309 - department_output_loss: 0.1649 - attrition_output_loss: 0.0660 - department_output_accuracy: 0.9498 - attrition_output_accuracy: 0.9830 - val_loss: 2.6792 - val_department_output_loss: 1.7678 - val_attrition_output_loss: 0.9113 - val_department_output_accuracy: 0.5544 - val_attrition_output_accuracy: 0.7925\n",
            "Epoch 60/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2296 - department_output_loss: 0.1700 - attrition_output_loss: 0.0595 - department_output_accuracy: 0.9507 - attrition_output_accuracy: 0.9889 - val_loss: 2.6260 - val_department_output_loss: 1.7360 - val_attrition_output_loss: 0.8901 - val_department_output_accuracy: 0.5408 - val_attrition_output_accuracy: 0.8061\n",
            "Epoch 61/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2098 - department_output_loss: 0.1519 - attrition_output_loss: 0.0579 - department_output_accuracy: 0.9524 - attrition_output_accuracy: 0.9847 - val_loss: 2.6777 - val_department_output_loss: 1.7923 - val_attrition_output_loss: 0.8855 - val_department_output_accuracy: 0.5306 - val_attrition_output_accuracy: 0.8333\n",
            "Epoch 62/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2002 - department_output_loss: 0.1417 - attrition_output_loss: 0.0585 - department_output_accuracy: 0.9651 - attrition_output_accuracy: 0.9847 - val_loss: 2.8104 - val_department_output_loss: 1.8335 - val_attrition_output_loss: 0.9770 - val_department_output_accuracy: 0.5680 - val_attrition_output_accuracy: 0.8197\n",
            "Epoch 63/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.1926 - department_output_loss: 0.1344 - attrition_output_loss: 0.0582 - department_output_accuracy: 0.9677 - attrition_output_accuracy: 0.9838 - val_loss: 2.8796 - val_department_output_loss: 1.9509 - val_attrition_output_loss: 0.9287 - val_department_output_accuracy: 0.5442 - val_attrition_output_accuracy: 0.8299\n",
            "Epoch 64/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2021 - department_output_loss: 0.1438 - attrition_output_loss: 0.0583 - department_output_accuracy: 0.9609 - attrition_output_accuracy: 0.9838 - val_loss: 2.8546 - val_department_output_loss: 1.9098 - val_attrition_output_loss: 0.9448 - val_department_output_accuracy: 0.5442 - val_attrition_output_accuracy: 0.8061\n",
            "Epoch 65/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1786 - department_output_loss: 0.1213 - attrition_output_loss: 0.0574 - department_output_accuracy: 0.9728 - attrition_output_accuracy: 0.9855 - val_loss: 2.9208 - val_department_output_loss: 1.9788 - val_attrition_output_loss: 0.9420 - val_department_output_accuracy: 0.5510 - val_attrition_output_accuracy: 0.8231\n",
            "Epoch 66/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1632 - department_output_loss: 0.1140 - attrition_output_loss: 0.0492 - department_output_accuracy: 0.9753 - attrition_output_accuracy: 0.9847 - val_loss: 2.9354 - val_department_output_loss: 1.9294 - val_attrition_output_loss: 1.0060 - val_department_output_accuracy: 0.5102 - val_attrition_output_accuracy: 0.7891\n",
            "Epoch 67/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1657 - department_output_loss: 0.1204 - attrition_output_loss: 0.0453 - department_output_accuracy: 0.9711 - attrition_output_accuracy: 0.9889 - val_loss: 3.0013 - val_department_output_loss: 2.0126 - val_attrition_output_loss: 0.9886 - val_department_output_accuracy: 0.5238 - val_attrition_output_accuracy: 0.8265\n",
            "Epoch 68/100\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.1672 - department_output_loss: 0.1220 - attrition_output_loss: 0.0452 - department_output_accuracy: 0.9660 - attrition_output_accuracy: 0.9889 - val_loss: 3.0161 - val_department_output_loss: 2.0179 - val_attrition_output_loss: 0.9982 - val_department_output_accuracy: 0.5340 - val_attrition_output_accuracy: 0.8129\n",
            "Epoch 69/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.1637 - department_output_loss: 0.1203 - attrition_output_loss: 0.0434 - department_output_accuracy: 0.9677 - attrition_output_accuracy: 0.9889 - val_loss: 3.0963 - val_department_output_loss: 2.0721 - val_attrition_output_loss: 1.0242 - val_department_output_accuracy: 0.5238 - val_attrition_output_accuracy: 0.8061\n",
            "Epoch 70/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.1507 - department_output_loss: 0.1078 - attrition_output_loss: 0.0429 - department_output_accuracy: 0.9736 - attrition_output_accuracy: 0.9906 - val_loss: 3.1083 - val_department_output_loss: 2.0567 - val_attrition_output_loss: 1.0516 - val_department_output_accuracy: 0.5238 - val_attrition_output_accuracy: 0.8027\n",
            "Epoch 71/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.1478 - department_output_loss: 0.0980 - attrition_output_loss: 0.0499 - department_output_accuracy: 0.9838 - attrition_output_accuracy: 0.9855 - val_loss: 3.1895 - val_department_output_loss: 2.1274 - val_attrition_output_loss: 1.0621 - val_department_output_accuracy: 0.5374 - val_attrition_output_accuracy: 0.7959\n",
            "Epoch 72/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.1352 - department_output_loss: 0.0930 - attrition_output_loss: 0.0422 - department_output_accuracy: 0.9813 - attrition_output_accuracy: 0.9838 - val_loss: 3.2359 - val_department_output_loss: 2.2012 - val_attrition_output_loss: 1.0347 - val_department_output_accuracy: 0.5442 - val_attrition_output_accuracy: 0.8197\n",
            "Epoch 73/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.1506 - department_output_loss: 0.1097 - attrition_output_loss: 0.0409 - department_output_accuracy: 0.9685 - attrition_output_accuracy: 0.9889 - val_loss: 3.2438 - val_department_output_loss: 2.1376 - val_attrition_output_loss: 1.1063 - val_department_output_accuracy: 0.5306 - val_attrition_output_accuracy: 0.7857\n",
            "Epoch 74/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.1317 - department_output_loss: 0.0929 - attrition_output_loss: 0.0388 - department_output_accuracy: 0.9796 - attrition_output_accuracy: 0.9906 - val_loss: 3.3120 - val_department_output_loss: 2.2244 - val_attrition_output_loss: 1.0877 - val_department_output_accuracy: 0.5238 - val_attrition_output_accuracy: 0.8027\n",
            "Epoch 75/100\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.1394 - department_output_loss: 0.0967 - attrition_output_loss: 0.0427 - department_output_accuracy: 0.9745 - attrition_output_accuracy: 0.9872 - val_loss: 3.2915 - val_department_output_loss: 2.2058 - val_attrition_output_loss: 1.0856 - val_department_output_accuracy: 0.5272 - val_attrition_output_accuracy: 0.8231\n",
            "Epoch 76/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1210 - department_output_loss: 0.0853 - attrition_output_loss: 0.0357 - department_output_accuracy: 0.9813 - attrition_output_accuracy: 0.9932 - val_loss: 3.3471 - val_department_output_loss: 2.2420 - val_attrition_output_loss: 1.1051 - val_department_output_accuracy: 0.5374 - val_attrition_output_accuracy: 0.7959\n",
            "Epoch 77/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1124 - department_output_loss: 0.0796 - attrition_output_loss: 0.0328 - department_output_accuracy: 0.9855 - attrition_output_accuracy: 0.9932 - val_loss: 3.4213 - val_department_output_loss: 2.2854 - val_attrition_output_loss: 1.1360 - val_department_output_accuracy: 0.5306 - val_attrition_output_accuracy: 0.8095\n",
            "Epoch 78/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.0990 - department_output_loss: 0.0713 - attrition_output_loss: 0.0277 - department_output_accuracy: 0.9847 - attrition_output_accuracy: 0.9957 - val_loss: 3.4690 - val_department_output_loss: 2.3387 - val_attrition_output_loss: 1.1304 - val_department_output_accuracy: 0.5238 - val_attrition_output_accuracy: 0.8163\n",
            "Epoch 79/100\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.1077 - department_output_loss: 0.0802 - attrition_output_loss: 0.0274 - department_output_accuracy: 0.9821 - attrition_output_accuracy: 0.9940 - val_loss: 3.5167 - val_department_output_loss: 2.3419 - val_attrition_output_loss: 1.1748 - val_department_output_accuracy: 0.5170 - val_attrition_output_accuracy: 0.7959\n",
            "Epoch 80/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1064 - department_output_loss: 0.0652 - attrition_output_loss: 0.0412 - department_output_accuracy: 0.9889 - attrition_output_accuracy: 0.9898 - val_loss: 3.6071 - val_department_output_loss: 2.3433 - val_attrition_output_loss: 1.2638 - val_department_output_accuracy: 0.5136 - val_attrition_output_accuracy: 0.7721\n",
            "Epoch 81/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1012 - department_output_loss: 0.0637 - attrition_output_loss: 0.0375 - department_output_accuracy: 0.9881 - attrition_output_accuracy: 0.9889 - val_loss: 3.6852 - val_department_output_loss: 2.4719 - val_attrition_output_loss: 1.2133 - val_department_output_accuracy: 0.5238 - val_attrition_output_accuracy: 0.7823\n",
            "Epoch 82/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.0991 - department_output_loss: 0.0645 - attrition_output_loss: 0.0346 - department_output_accuracy: 0.9906 - attrition_output_accuracy: 0.9881 - val_loss: 3.6534 - val_department_output_loss: 2.4347 - val_attrition_output_loss: 1.2187 - val_department_output_accuracy: 0.5340 - val_attrition_output_accuracy: 0.7857\n",
            "Epoch 83/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.0940 - department_output_loss: 0.0673 - attrition_output_loss: 0.0267 - department_output_accuracy: 0.9838 - attrition_output_accuracy: 0.9932 - val_loss: 3.5897 - val_department_output_loss: 2.3977 - val_attrition_output_loss: 1.1919 - val_department_output_accuracy: 0.5068 - val_attrition_output_accuracy: 0.8367\n",
            "Epoch 84/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.0911 - department_output_loss: 0.0647 - attrition_output_loss: 0.0264 - department_output_accuracy: 0.9881 - attrition_output_accuracy: 0.9932 - val_loss: 3.6961 - val_department_output_loss: 2.4787 - val_attrition_output_loss: 1.2173 - val_department_output_accuracy: 0.5238 - val_attrition_output_accuracy: 0.8027\n",
            "Epoch 85/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.0793 - department_output_loss: 0.0543 - attrition_output_loss: 0.0250 - department_output_accuracy: 0.9949 - attrition_output_accuracy: 0.9940 - val_loss: 3.8141 - val_department_output_loss: 2.6135 - val_attrition_output_loss: 1.2006 - val_department_output_accuracy: 0.5544 - val_attrition_output_accuracy: 0.7925\n",
            "Epoch 86/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.0882 - department_output_loss: 0.0585 - attrition_output_loss: 0.0297 - department_output_accuracy: 0.9898 - attrition_output_accuracy: 0.9923 - val_loss: 3.6156 - val_department_output_loss: 2.4381 - val_attrition_output_loss: 1.1775 - val_department_output_accuracy: 0.5238 - val_attrition_output_accuracy: 0.8163\n",
            "Epoch 87/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.0758 - department_output_loss: 0.0503 - attrition_output_loss: 0.0255 - department_output_accuracy: 0.9940 - attrition_output_accuracy: 0.9915 - val_loss: 3.8172 - val_department_output_loss: 2.5737 - val_attrition_output_loss: 1.2435 - val_department_output_accuracy: 0.5204 - val_attrition_output_accuracy: 0.8095\n",
            "Epoch 88/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.0709 - department_output_loss: 0.0476 - attrition_output_loss: 0.0233 - department_output_accuracy: 0.9949 - attrition_output_accuracy: 0.9940 - val_loss: 3.8052 - val_department_output_loss: 2.5427 - val_attrition_output_loss: 1.2625 - val_department_output_accuracy: 0.5136 - val_attrition_output_accuracy: 0.7857\n",
            "Epoch 89/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.0823 - department_output_loss: 0.0591 - attrition_output_loss: 0.0232 - department_output_accuracy: 0.9872 - attrition_output_accuracy: 0.9932 - val_loss: 3.8641 - val_department_output_loss: 2.6033 - val_attrition_output_loss: 1.2608 - val_department_output_accuracy: 0.4864 - val_attrition_output_accuracy: 0.7959\n",
            "Epoch 90/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.0795 - department_output_loss: 0.0625 - attrition_output_loss: 0.0170 - department_output_accuracy: 0.9881 - attrition_output_accuracy: 0.9966 - val_loss: 4.0827 - val_department_output_loss: 2.7503 - val_attrition_output_loss: 1.3324 - val_department_output_accuracy: 0.5204 - val_attrition_output_accuracy: 0.8061\n",
            "Epoch 91/100\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.0751 - department_output_loss: 0.0480 - attrition_output_loss: 0.0271 - department_output_accuracy: 0.9923 - attrition_output_accuracy: 0.9906 - val_loss: 4.1312 - val_department_output_loss: 2.7923 - val_attrition_output_loss: 1.3389 - val_department_output_accuracy: 0.5238 - val_attrition_output_accuracy: 0.7993\n",
            "Epoch 92/100\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.0764 - department_output_loss: 0.0479 - attrition_output_loss: 0.0284 - department_output_accuracy: 0.9932 - attrition_output_accuracy: 0.9923 - val_loss: 4.0028 - val_department_output_loss: 2.7289 - val_attrition_output_loss: 1.2740 - val_department_output_accuracy: 0.5238 - val_attrition_output_accuracy: 0.8095\n",
            "Epoch 93/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.0593 - department_output_loss: 0.0429 - attrition_output_loss: 0.0165 - department_output_accuracy: 0.9932 - attrition_output_accuracy: 0.9949 - val_loss: 3.9804 - val_department_output_loss: 2.6614 - val_attrition_output_loss: 1.3190 - val_department_output_accuracy: 0.5306 - val_attrition_output_accuracy: 0.7993\n",
            "Epoch 94/100\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0626 - department_output_loss: 0.0431 - attrition_output_loss: 0.0195 - department_output_accuracy: 0.9940 - attrition_output_accuracy: 0.9932 - val_loss: 4.0655 - val_department_output_loss: 2.6769 - val_attrition_output_loss: 1.3886 - val_department_output_accuracy: 0.5136 - val_attrition_output_accuracy: 0.7619\n",
            "Epoch 95/100\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0585 - department_output_loss: 0.0397 - attrition_output_loss: 0.0188 - department_output_accuracy: 0.9957 - attrition_output_accuracy: 0.9957 - val_loss: 4.1444 - val_department_output_loss: 2.7610 - val_attrition_output_loss: 1.3834 - val_department_output_accuracy: 0.5238 - val_attrition_output_accuracy: 0.7823\n",
            "Epoch 96/100\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0631 - department_output_loss: 0.0401 - attrition_output_loss: 0.0230 - department_output_accuracy: 0.9949 - attrition_output_accuracy: 0.9932 - val_loss: 4.2212 - val_department_output_loss: 2.8626 - val_attrition_output_loss: 1.3586 - val_department_output_accuracy: 0.5408 - val_attrition_output_accuracy: 0.8095\n",
            "Epoch 97/100\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0675 - department_output_loss: 0.0419 - attrition_output_loss: 0.0256 - department_output_accuracy: 0.9923 - attrition_output_accuracy: 0.9932 - val_loss: 4.2291 - val_department_output_loss: 2.8808 - val_attrition_output_loss: 1.3483 - val_department_output_accuracy: 0.5034 - val_attrition_output_accuracy: 0.7959\n",
            "Epoch 98/100\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0684 - department_output_loss: 0.0416 - attrition_output_loss: 0.0268 - department_output_accuracy: 0.9932 - attrition_output_accuracy: 0.9915 - val_loss: 4.1881 - val_department_output_loss: 2.8225 - val_attrition_output_loss: 1.3657 - val_department_output_accuracy: 0.5272 - val_attrition_output_accuracy: 0.7789\n",
            "Epoch 99/100\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0676 - department_output_loss: 0.0406 - attrition_output_loss: 0.0270 - department_output_accuracy: 0.9966 - attrition_output_accuracy: 0.9915 - val_loss: 4.2127 - val_department_output_loss: 2.8666 - val_attrition_output_loss: 1.3461 - val_department_output_accuracy: 0.5034 - val_attrition_output_accuracy: 0.8163\n",
            "Epoch 100/100\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0706 - department_output_loss: 0.0407 - attrition_output_loss: 0.0299 - department_output_accuracy: 0.9940 - attrition_output_accuracy: 0.9889 - val_loss: 4.3493 - val_department_output_loss: 3.0389 - val_attrition_output_loss: 1.3104 - val_department_output_accuracy: 0.5476 - val_attrition_output_accuracy: 0.7585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the testing data and print the results\n",
        "total_samples = X_test_scaled_final.shape[0]\n",
        "batches = 11\n",
        "batch_size = max(total_samples // batches, 1)  # Ensure batch_size is at least 1\n",
        "\n",
        "# Re-evaluate the model with the calculated batch size\n",
        "evaluation_results = model.evaluate(\n",
        "    x=X_test_scaled_final,\n",
        "    y={'department_output': department_test_encoded, 'attrition_output': attrition_test_encoded},\n",
        "    batch_size=batch_size,\n",
        "    verbose=1\n",
        ")\n",
        "evaluation_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjtPW9C32Idz",
        "outputId": "cf4d2390-9897-4438-aa6e-aa606f60439f"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 3ms/step - loss: 4.3493 - department_output_loss: 3.0389 - attrition_output_loss: 1.3104 - department_output_accuracy: 0.5476 - attrition_output_accuracy: 0.7585\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.349291801452637,\n",
              " 3.03887939453125,\n",
              " 1.3104126453399658,\n",
              " 0.5476190447807312,\n",
              " 0.7585033774375916]"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the accuracy for the department output\n",
        "print(f\"Department predictions accuracy: {evaluation_results[-2]}\")\n",
        "\n",
        "# Print the accuracy for the attrition output\n",
        "print(f\"Attrition predictions accuracy: {evaluation_results[-1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpTuu0hs2I-M",
        "outputId": "e5ecd6fe-7d5b-4363-d265-c1fca4de3251"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Department predictions accuracy: 0.5476190447807312\n",
            "Attrition predictions accuracy: 0.7585033774375916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGSyfsZfWOQM"
      },
      "source": [
        "# Summary\n",
        "\n",
        "In the provided space below, briefly answer the following questions.\n",
        "\n",
        "1. Is accuracy the best metric to use on this data? Why or why not?\n",
        "\n",
        "2. What activation functions did you choose for your output layers, and why?\n",
        "\n",
        "3. Can you name a few ways that this model might be improved?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi9SLpFnWvbF"
      },
      "source": [
        "YOUR ANSWERS HERE\n",
        "\n",
        "1. Accuracy may not always be the best metric to use, especially if the data is unbalanced. In the given dataset, if the number of employees who left the company ('Yes' in Attrition) is significantly lower than those who stayed ('No'), then the model might be biased towards predicting 'No' for Attrition. This would yield a high accuracy simply because the most common class is being predicted more often, not necessarily because the model is good at predicting actual attrition cases. In such cases, other metrics like Precision, Recall, F1 Score, or the Area Under the Receiver Operating Characteristic Curve (AUC-ROC) might provide a better understanding of the model's performance.\n",
        "2. For the Department output, a 'softmax' activation function is used because it is a multi-class classification problem. 'Softmax' is suitable here because it converts the output into a probability distribution across the different Department classes, which is useful for classification.\n",
        "For the Attrition output, it seems a 'sigmoid' activation function might have been more appropriate if it was a binary classification (yes/no). However, since a 'softmax' function was used, it suggests that the Attrition was treated as a two-class problem, potentially due to one-hot encoding of the binary response, which turns it into two separate outputs (effectively making it similar to a multi-class problem).\n",
        "3. Data Balancing: If the classes are imbalanced, techniques like oversampling the minority class, undersampling the majority class, or using synthetic data generation techniques like SMOTE can help improve model performance by providing a more balanced view of the classes.\n",
        "Hyperparameter Tuning: Adjusting the learning rate, experimenting with different optimizers, and tuning the number of neurons or layers can potentially improve the model's accuracy.\n",
        "Advanced Architectures: Incorporating more sophisticated neural network architectures like recurrent neural networks (RNNs) for sequence data, or convolutional neural networks (CNNs) for grid data, can capture complex patterns better.\n",
        "Regularization: To prevent overfitting, regularization techniques like dropout, L1/L2 regularization, or using early stopping during training could be beneficial.\n",
        "Feature Engineering: Creating new features or modifying existing ones could provide the model with more meaningful data, leading to better performance.\n",
        "Cross-Validation: Instead of a single train-test split, using k-fold cross-validation ensures that the model's performance is consistent across different subsets of the data.\n",
        "Ensemble Methods: Using an ensemble of models and combining their predictions could lead to better generalization and robustness.\n",
        "Evaluation Metrics: Considering other metrics like Precision, Recall, F1 score, or the ROC-AUC curve for evaluation, especially if dealing with imbalanced data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD5YQRUFV7xw"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}